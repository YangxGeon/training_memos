# DAY1

## 강사 정보

- __이름:__ 최국현
- __메일주소:__ tang/앙/linux.com
- __점심시간:__ 12시 30분부터 01시 30분까지
- __쉬는시간:__ 15분

>https://github.com/tangt64/training_memos/
>opensource/kubernetes-101
>20230915-memo.md

- [리눅스 깃헙/메모/교재 주소](https://github.com/tangt64/training_memos/tree/main/opensource/kubernetes-101)

# 마지막날(ㅠㅠ)

1. MSA/3 tiers그대로 유지할것인가? 아니면 전환할것인가?

MSA: 데이터베이스 문제!! Pod(applications)
- Oracle -> PgSQL(쪼개기+소형화)

3tier: 컨테이너화 혹은 가상화로 운영할지 
- kube-virt기존 서비스 가져오기(libvirtd)
- 기존서비스 유지 + 컨테이너 기반으로 확장

쿠버네티스의 최대 차이점
- 아이피 및 저장소 부분은 유동적이다
- 소프트웨어 핸들링, 고정적인 정보를 가지고 동작하는 소프트웨어는 쿠버네티스에서 잘 동작하지 않을수 있음

조합(??)
---
1. VMware(tanzu) + Kubernetes(1)
2. OpenStack + Kubernetes(2)
3. ovirt + kubernetes(3)
4. Hyperv + Kubernetes(for lab)
5. Kubernetes(kube-virt)

조건
---
VM * 2, Rocky Linux 9.2

node1(vcpu 2, vmem 3GiB, disk 100 Gib)
node2(vcpu 2, vmem 3Gib, disk 100 Gib)


node1/2 설정(hyper-v)
---
__UEFI:__ 마이크로소프트사 인증 기관
__MEMORY:__ 동적메모리 기능 끄기, 2048~4096(4GiB)
__DISK:__ 기본값 그대로 사용
__PACKAGE:__ 최소설치(게스트 에이전트, 표준설치)
__ROOT ACCOUNT:__ root로그인 가능


THE CIQ
---
1. https://www.reddit.com/r/linuxadmin/comments/15p1gbt/why_so_much_hate_for_ciq/
2. https://www.reddit.com/r/redhat/comments/15nkj3e/oracle_suse_and_ciq_go_after_red_hat_with_the/
3. https://www.reddit.com/r/AlmaLinux/comments/15dr141/giving_rebuilders_a_bad_name_ciq_and_ansible/


1. 하이브리드 형식


```bash

1. 기존 리소스 활용이 높음
2. 컨테이너는 가상화 기술이 아님
3. 순수 컨테이너 기술 기반(MSA)
4. 게이트웨어 용도로 사용하는 경우()


  [kubernetes]
       |
    +-----+    +-----+
    | vm1 |    | vm2 | + N(VM)
    +-----+    +-----+
         \     /
          \   /q
           \ /
          [H/V] (RING)
            |
            |
            |
  -----------------------
  Virtualization Platform
[rhv,vmware,openstack,HCI]
        [PaaS,IaaS]        
  -----------------------


```



2. 베어메탈 형식

```bash
- Virtualization
- SR-IOV
- DPDK/eBPF


                       .---- [VIRTUAL_MACHINE]
                      / 
    {RUNTIME} ---> [POD] --- [CONTAINER]
        |
    +------+     
    | node |   
    +------+     

```

```bash

master/node]# nmcli con up eth0

master/node]# cat <<EOF>> /etc/hosts
192.168.90.250 master.example.com master
192.168.90.120 node1.example.com node1
EOF
master/node]# cat /etc/hosts

master]# hostnamectl set-hostname master.example.com
node1]# hostnamectl set-hostname node1.example.com
master/node]# hostname

master/node]# dnf update -y         ## 여기서는 하지마세요!!

master/node]# dnf search kubeadm
master/node]# cat <<EOF> /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.26/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.26/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
master/node]# dnf search kubeadm
master/node]# dnf install --disableexcludes=kubernetes kubeadm


master/node]# cat <<EOF> /etc/modules-load.d/k8s-modules.conf
br_netfilter
overlay
EOF
master/node]# modprobe br_netfilter
master/node]# modprobe overlay
master/node]# lsmod | grep -e br_netfilter -e overlay


master/node]# cat <<EOF> /etc/sysctl.d/99-k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
master/node]# sysctl --system

#
# CRI-O 컨테이너 런타임(엔진)(저수준)
#

master/node]# wget https://raw.githubusercontent.com/tangt64/duststack-k8s-auto/master/roles/kubernetes/k8s-prepare/files/devel_kubic_libcontainers_stable.repo -O /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo
master/node]# wget https://raw.githubusercontent.com/tangt64/duststack-k8s-auto/master/roles/kubernetes/k8s-prepare/files/devel_kubic_libcontainers_stable_crio.repo -O /etc/yum.repos.d/devel_kubic_libcontainers_stable_crio.repo
master/node]# ls -l /etc/yum.repos.d/                       ## /etc/dnf/repos.d/
> devel_kubic_libcontainers_stable.repo
> devel_kubic_libcontainers_stable_crio.repo
master/node]# dnf install crio -y


master/node]# systemctl stop firewalld
master/node]# systemctl disable firewalld
master/node]# dnf install iproute-tc -y
master/node]# swapoff -a
master/node]# sed -i '/ swap / s/^/#/' /etc/fstab
master/node]# sed -i s/^SELINUX=.*$/SELINUX=permissive/ /etc/selinux/config
master/node]# getenforce
master/node]# setenforce 0

master]# nmcli con add con-name eth1 ipv4.method manual ipv4.addresses 192.168.90.250/24 ifname eth1 type ethernet
master]# nmcli con up eth1
master]# ip a s eth1
> 192.168.90.250

node]# nmcli con add con-name eth1 ipv4.method manual ipv4.addresses 192.168.90.120/24 ifname eth1 type ethernet
node]# nmcli con up eth1
node]# ip a s eth1
> 192.168.90.120

node]# ping 192.168.90.250 -c2
master]# ping 192.168.90.120 -c2 

master/node]# systemctl enable --now crio
master/node]# systemctl enable --now kubelet 

master/node]# wget https://raw.githubusercontent.com/tangt64/training_memos/main/opensource/kubernetes-101/files/policy.json -O /etc/containers/policy.json

master]# kubeadm reset --force
master]# kubeadm init --apiserver-advertise-address=192.168.90.250 \
--pod-network-cidr=192.168.0.0/16 \
--service-cidr=10.90.0.0/16 

> kubeadm join 192.168.90.250:6443 --token hf7c2h.jiym17oow7khrqm2 \
        --discovery-token-ca-cert-hash sha256:be02bee19f4431d34e1ee7d6dfde4bc29936b3b47739e4b07a52527dd54cf503

node]# kubeadm join 192.168.90.250:6443 --token hf7c2h.jiym17oow7khrqm2 \
        --discovery-token-ca-cert-hash sha256:be02bee19f4431d34e1ee7d6dfde4bc29936b3b47739e4b07a52527dd54cf503

master]# export KUBECONFIG=/etc/kubernetes/admin.conf
master]# kubectl get nodes
master]# kubectl get pods


master]# kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/tigera-operator.yaml
master]# kubectl create -f https://raw.githubusercontent.com/tangt64/training_memos/main/opensource/kubernetes-101/calico-quay-crd.yaml
master]# kubectl get pods -wA   


master]# kubectl completion bash >> .bashrc     

master]# kubectl run --image=quay.io/centos/centos:stream9 k8s-bootcamp --dry-run=client --output=yaml /bin/sleep 10000 > bootcamp-centos.yaml
master]# kubectl apply -f bootcamp-centos.yaml
master]# kubectl get pods -w
> k8s-bootcamp   0/1     ContainerCreating   0          5s 
> k8s-bootcamp   1/1     Running             0          18s 

node]# systemctl is-active crio
> active

# containerd(docker분리, 표준)
# cri-o(현재 더 많이 선호)
# mirantis-docker(cri-docker)

node]# crictl ps                     ## 컨테이너 목록
node]# crictl pods lsmod             ## 포드(팟) 목록


node]# crictl images
> pause
node]# dnf install podman -y
node]# podman images
node]# cd ~
node]# podman save registry.k8s.io/pause:3.6 -o pause.tar
> Copying blob 1021ef88c797 done
> Copying config 6270bb605e done
> Writing manifest to image destination
> Storing signatures
node]# mkdir pause_disk
node]# tar xf pause.tar -C pause_disk/
node]# cd paseu_disk/
node]# tar xf 1021ef88c7974bfff89c5a0ec4fd3160daac6c48a075f74cff721f85dd104e68.tar
node]# ls                                 # pause
node]# ./pause

node]# podman run -d --rm --name k8s-bootcamp quay.io/centos/centos:stream9 /bin/sleep 10000 
node]# podman stop k8s-bootcamp
node]# podman rm k8s-bootcamp
node]# podman container ls
node]# podman run -d --pod new:pod-k8s-bootcamp --rm --name k8s-bootcamp quay.io/centos/centos:stream9 /bin/sleep 10000 
node]# podman pod ls
node]# podman container ls
master/node]# lsns -t mnt
                      net
node]# podman pod inspect pod-k8s-bootcamp



master]# kubectl run --image=quay.io/redhattraining/hello-world-nginx bootcamp-nginx
master]# kubectl expose pod bootcamp-nginx --port=8080 --protocol=TCP
master]# kubectl get svc
> bootcamp-nginx   ClusterIP   10.90.27.8   <none>        8080/TCP   25m  
master]# ip a s eth0
> 172.x.x.x.
master]# kubectl port-forward service/bootcamp-nginx --address 172.23.193.218 8080:8080
master]# kubectl get pod

master]# kubectl create deployment deploy-bootcamp-nginx --image=quay.io/redhattraining/hello-world-nginx --replicas=10 --port=8080 --output=yaml --dry-run=client > deploy-bootcamp-nginx.yaml 
master]# kubectl apply -f deploy-bootcamp-nginx.yaml
master]# kubectl get deploy -w
master]# kubectl get pods 

master]# kubectl get deploy
master]# kubectl expose deployment deploy-bootcamp-nginx --type=NodePort  
master]# kubectl get svc
> deploy-bootcamp-nginx   NodePort    10.90.228.232   <none>        8080:30056/TCP   42s     
> master:eth0
> node:eth0
```


NFS
---

!!!모든 작업은 마스터 서버에서 진행 합니다!!!

```bash
master/node]# dnf install nfs-utils -y
master]# systemctl enable --now nfs-server
master]# mkdir -p /nfs/
master]# cat <<EOF> /etc/exports
/nfs *(rw,sync)
EOF
master]# exportfs -avrs
master]# showmount -e master.example.com
> Export list for master.example.com:
> /nfs *

master]# cat <<EOF> storageclass-sa.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  name: nfs-pod-provisioner-sa
EOF
master]# kubectl apply -f storageclass-sa.yaml

master]# cat <<EOF> storageclass-clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-provisioner-clusterRole
rules:
  - apiGroups: [""] # rules on persistentvolumes
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
EOF
master]# kubectl apply -f storageclass-clusterrole.yaml

master]# cat <<EOF> storageclass-clusterrolebind.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-provisioner-rolebinding
subjects:
  - kind: ServiceAccount
    name: nfs-pod-provisioner-sa
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-provisioner-clusterRole
  apiGroup: rbac.authorization.k8s.io
EOF
master]# kubectl apply -f storageclass-clusterrolebind.yaml

master]# cat <<EOF> storageclass-role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-pod-provisioner-otherRoles
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
EOF
master]# kubectl apply -f storageclass-role.yaml

master]# cat <<EOF> storageclass-rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-pod-provisioner-otherRoles
subjects:
  - kind: ServiceAccount
    name: nfs-pod-provisioner-sa
    namespace: default
roleRef:
    kind: Role
    name: nfs-pod-provisioner-otherRoles
    apiGroup: rbac.authorization.k8s.io
EOF
master]# kubectl apply -f storageclass-rolebinding.yaml

master]# cat <<EOF> storageclass-configure.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-csi
provisioner: nfs.csi.k8s.io
parameters:
  server: master.example.com
  share: /nfs
reclaimPolicy: Delete
volumeBindingMode: Immediate
mountOptions:
  - hard
  - nfsvers=4.1
EOF
master]# kubectl apply -f storageclass-configure.yaml

master]# cat <<EOF> storageclass-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-nfs-dynamic
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: nfs-csi
EOF

master]# kubectl apply -f storageclass-configure.yaml
master]# kubectl apply -f storageclass-pvc.yaml

master]# kubectl get sc
master]# kubectl get pvc

master]# kubectl describe pvc pvc-nfs-dynamic


master]# cat <<EOF> nfs-csi-pod.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: nfs-csi-pod
spec:
  selector:
    matchLabels:
      app: nfs-csi-pod
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: nfs-csi-pod
    spec:
      serviceAccountName: nfs-pod-provisioner-sa  ## csi-nfs-controller-sa
      containers:
        - name: sc-nginx
          image: quay.io/redhattraining/hello-world-nginx
          volumeMounts:
            - name: csi-nfs
              mountPath: /usr/share/nginx/html
          ports:
            - containerPort: 8080
#  volumes:
#    - name: config
#      persistentVolumeClaim:
#        claimName: pvc-nfs-dynamic

      volumes:
       - name: csi-nfs
         nfs:
           server: master.example.com
           path: /nfs
EOF

master]# kubectl apply -f nfs-csi-pod.yaml

master]# kubectl get pods
master]# kubectl get sc
master]# kubectl get pvc
master]# kubectl get pv
master]# kubectl expose deployment nfs-csi-pod --type NodePort --name nfs-csi-pod-nodeport
master]# kubectl describe pod nfs-csi-pod-xxxx
> Mounts:
master]# kubectl exec -it nfs-csi-pod-xxxx -- ls /usr/share/nginx/html
> pvc-4d515fba-62a1-4853-b26a-8f5a02d550b1
master]# curl localhost:<NODE_PORT>/index.html
> ERROR

#  volumes:
#    - name: csi-nfs
#      persistentVolumeClaim:
#        claimName: pvc-nfs-dynamic

EOF

master]# kubectl get sc -A
master]# cat <<EOF> manual-pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
  labels:
    type: nfs
spec:
  storageClassName: ""
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
nfs:
    server: master.example.com
    share: "/nfs/manual-pv"
EOF
master]# kubectl apply -f manual-pv.yaml

master]# cat <<EOF> pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  storageClassName: ""
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
EOF
master]# kubectp apply -f pvc.yaml
master]# cat <<EOF> manual-pvc-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pvc-pod
spec:
  containers:
  - name: pvc-pod
    image: nginx
    volumeMounts:
      - mountPath: "/app/data"
        name: htdocs
  volumes:
  - name: htdocs
    persistentVolumeClaim:
      claimName: nfs-pvc
EOF
master]# kubectl apply -f pvc-pod.yaml
master]# kubectl scribe pod/nfs-csi-pod-xxx | grep -A3 Mount
> Mounts:
>   /usr/share/nginx/html from csi-nfs (rw)
>   /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nlf8n (ro)
> Mounting arguments: -t nfs master.example.com:/nfs /var/lib/kubelet/pods/e08b44f7-5b9f-45dc-aab0-7954e1a2933f/volumes/kubernetes.io~nfs/csi-nfs
master]# echo "Hello world" > /nfs/index.html
master]# kubectl exec -it pod/nfs-csi-pod-xxx -- /bin/bash
> cat /proc/1/comm
> pause
```

[NOFBI](https://www.wolf.university/masteringkubernetes/ebook/masteringkubernetes_thirdedition.pdf)

- POD는 개념, 쿠버네티스에서 사용하는 격리 단위
- infra container(Pod)
- Pod == Infra Container == Pause(프로그램)
- Pause(Pod(Infra_Container))
- 바닐라 쿠버네티스는 Pause, 다른 OpenShift, Rancher와 같은 도구는 다른 Pause프로그램 사용
- knative: kn, serverless for service
- kubernetes: kubectl, for infrastructure 
- tekton: tkn, CD for delivery