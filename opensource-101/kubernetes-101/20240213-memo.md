# DAY 1

- 이름: 최국현
- 메일: tang@linux.com

__쉬는시간:__ 15분

__점심시간:__ 12시부터 01시 20분까지.

메모파일 및 교재
---
https://github.com/tangt64/training_memos/
>/opensource-101/kubernetes-101/20240213-memo.md


화이트보드
---
https://wbd.ms/share/v2/aHR0cHM6Ly93aGl0ZWJvYXJkLm1pY3Jvc29mdC5jb20vYXBpL3YxLjAvd2hpdGVib2FyZHMvcmVkZWVtLzdkNGM4ZTBiMTJhZDRhNTRhYTNkMGRmNWI0N2NkNTY5X0JCQTcxNzYyLTEyRTAtNDJFMS1CMzI0LTVCMTMxRjQyNEUzRF81NzVjMDQ0Mi1hNmU5LTRmNGYtYjY2MS1jNzg0NzcyMGU1ODg=


연습 혹은 실무적 수준으로 랩 구성
---

kubeadm명령어 기반으로 설치
>공식 설치 도구
>강의 진행은 __kubeadm__ 기반으로 진행

minikube/kind는 사용하지 말기.
>AIO/SNO
>master x 1, worker x 2 --> 5EA
>master x 3, L/B Server(VIP), Pacemaker  

자동화 도구
>kubespray(ansible)
>terraform

플랫폼 조합(?)
---
- OpenStack + Kubernetes
- LDAP/FreeIPA(https://www.freeipa.org/)
- Operator(https://sdk.operatorframework.io/)


소프트웨어
---
1. crio(containerd)
2. container-tools(표준 컨테이너 도구)
3. containerd(https://github.com/Mirantis/cri-dockerd) 권장
4. CentOS/Rocky/RHEL/Debian(ubuntu)
5. calico


랩 사양(PoC)
---
- CPU: I5이상에, 8core권장
- MEM: 32GiB이상
- DISK: 1TB, NvME/SSD
- NIC: 1G~10G(baremetal 3G이상)
- OS: Windows 11 Pro + Hyver-V, Rocky Linux 9, CentOS-Stream


## 설치 준비


- [공식 설치 문서](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
- [OSTREE](https://github.com/ostreedev/ostree)
- [CRIO RUNTIME](https://cri-o.io/)


```bash
dnf search hyper
>hyperv-daemons.x86_64 : Hyper-V daemons suite
>hyperv-daemons-license.noarch : License of the Hyper-V daemons suite
>hyperv-tools.noarch : Tools for Hyper-V guests
>hypervfcopyd.x86_64 : Hyper-V FCOPY daemon
>hypervkvpd.x86_64 : Hyper-V key value pair (KVP) daemon
>hypervvssd.x86_64 : Hyper-V VSS daemon

dnf install -y hyperv-tools hypervfcopyd hypervkvpd hypervvssd hyperv-daemons
reboot

dnf search ostree             ## rhcos, fedora coreos
                    ## ostree, RPM기반


curl -o /etc/yum.repos.d/stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_9_Stream/devel:kubic:libcontainers:stable.repo

curl -o /etc/yum.repos.d/crio.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.24:/1.24.6/CentOS_8/devel:kubic:libcontainers:stable:cri-o:1.24:1.24.6.repo

dnf repolist
dnf search cri-o
dnf install -y cri-o

lsns                  ## 네임스페이스 조회
systemd-cgls              ## cgroup 조회


#
# https://v1-27.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
# 설치는 버전 1.27로 진행(추후 업그레이드 테스트)
# 

cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.27/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.27/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF

dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

systemctl enable --now crio
systemctl enable --now kubelet

systemctl is-active crio kubelet
```


쿠버네티스 클러스터 최소 구성 요구사항
---
  One or more machines running a deb/rpm-compatible Linux OS; for example: Ubuntu or CentOS.
  2 GiB or more of RAM per machine--any less leaves little room for your apps.
  At least 2 CPUs on the machine that you use as a control-plane node.
  Full network connectivity among all machines in the cluster. You can use either a public or a private network.

- NIC: 2개
- CPU: 2개
- MEM: 2기가

1. OS를 최신버전으로 업데이트
2. 네트워크 설정

```bash
# /etc/hosts에 A레코드 임시로 명시
vi /etc/hosts
> 192.168.10.1  master1.example.com master1
> 192.168.10.2  node1.example.com node1
> 192.168.10.3  node2.example.com node2


# 이전 네트워크 ifcfg-rh스크립트는 아래 명령어로 처리
nmcli con migrate

# master, node에 동일하게 적용
nmcli con sh
nmcli con mod eth1 ipv4.addresses 192.168.10.1/24         
nmtui edit eth1                          ## TUI기반으로 수정
> IPV4ADDR: 192.168.10.[1..3]/24
> IPV4GW: NONE
> [X] Never use this network for default route  
nmcli con up eth1                        ## nmcli con reload eth1
ip a s eth1

swapon -s
swapoff -a
vi /etc/fstab
systemctl daemon-reload
```

1. 쿠버네티스는 SWAP이 필요가 없다.

network script
---
1. ifcfg-rh
2. ifcfg-suse
3. ifcfg-debian

__systemd__ 를 사용하면서 통합. 

1. NetworkManager(RH)
2. systemd-networkd

```bash
NetworkManager --print-config
cat /etc/NetworkManager/NetworkManager.conf
```

방화벽
---
1. iptables -> nftables변경
2. 고수준 방화벽은 firewalld가 기본(모든 배포판)

```bash
firewall-cmd --get-services | grep kube

for i in kube-api kube-apiserver kube-control-plane kube-control-plane-secure kube-controller-manager kube-controller-manager-secure kube-nodeport-services kube-scheduler kube-scheduler-secure kube-worker kubelet kubelet-readonly kubelet-worker ; do firewall-cmd --add-service=${i} ; done
firewall-cmd --runtime-to-permanent
firewall-cmd --list-all


# 랩에서는 끄고 사용

systemctl disable firewalld
systemctl stop firewalld
```

커널 모듈 및 파라메터(control, worker)
---

```bash
modprobe br_netfilter
lsmod | grep br_netfilter
vi /etc/modules-load.d/10-k8s.conf
> br_netfilter
systemctl daemon-reload

sysctl -w net.ipv4.ip_forward=1
echo net.ipv4.ip_forward=1 > /etc/sysctl.d/10-k8s.conf
sysctl --system
sysctl -a | grep net.ipv4.ip_forward
systemctl daemon-reload
```

설치 테스트
---

```bash
master]# kubeadm init
master]# kubeadm reset --force

kubeadm init phase preflight

## 기본 클러스터 이름은 kubernetes
## 기본 클러스터 도메인은 cluster.local
## 위의 내용을 변경하려면, YAML작성

kubeadm init --apiserver-advertise-address=192.168.10.1 --pod-network-cidr  --service-cidr --service-dns-domain=cluster.local --upload-certs 

## POD네트워크 Pod to Pod의 터널링 네트워크
## SVC네트워크 nftables(iptables)에서 사용하는 SEP(Sevice Endpoint) S/DNAT구현해주는 영역

master]# kubeadm init --apiserver-advertise-address=192.168.10.1 --pod-network-cidr=192.168.0.0/16  --service-cidr=10.1.0.0/16
master]# kubeadm token create --print-join-command

      +-------------+                     +----------+
      |   master1   |                     |  node1   |
      |  [cluster]  |  <---- join ----    | [worker] |
      |  kubernetes |         \           +----------+
      +-------------+          \
                                \
                                 `---> kubeadm join 192.168.10.1:6443 --token bd8j7f.ehaewaeuagnoftpc \
        --discovery-token-ca-cert-hash sha256:2b2af82e2aeb66d94dd49e63e38359091fea5e72244fecfd9fd8a9aff5


KUBECONFIG=/etc/kubernetes/admin.conf kubectl get nodes
> localhost.localdomain
hostnamectl set-hostname master1.example.com
                         node1.example.com
                         node2.example.com        
```

## 컨테이너 및 쿠버네티스 구성 및 구성원

1. runtime filesystem

- /etc/containers/
- /var/lib/containers/storage/overlay
- /run/containers/
- /run/pod/


```bash
lsmod | grep overlay            ## mount
> backingFsBlockDev             ## as block storage

systemctl status kubelet
> kubelet.service - kubelet: The Kubernetes Node Agent
  --------------
  1. 쿠버네티스 설치(이미지 내려받기 및 기본설정)
  2. 컨테이너 기반으로 서비스 구성

crictl pods ls                  ## Pod 컨테이너(인프라)
crictl ps                       ## 컨테이너(애플리케이션)


                          namespace(ipc,mnt,uts,net...)

pod        pause       infra-container
---        -----       ---------------
cgroup     httpd       app-container
namespace

dnf install -y podman 
podman save 6270bb605e12 -o pause.tar
mkdir pause
tar xf pause.tar -C pause
cd pause
tar xf <TAR>

     .---> infra-container
    /
./pause httpd -DFOREGROUND                    ## cgroup+namespace
------- -----                                 ## limit, mount
  POD    APP
    \
     `---> abstration


          kube-proxy/kubelet
                  |
                  |
                CRIO 
        -------------------------
        pod  |  <--->  | container
                  |
                  |
                conmon
     (container monitor utility)
                  |
                  |
                 runc                 ## low level runtime
      (crun, container creator) --- POD
                                    Container

export KUBECONFIG=/etc/kubernetes/admin.conf
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml

curl https://raw.githubusercontent.com/tangt64/training_memos/main/opensource-101/kubernetes-101/calico-quay-crd.yaml -o calico-quay-crd.yaml 
vi calico-quay-crd.yaml
> - blockSize: 26 
>   cidr: 192.168.0.0/16
kubectl apply -f calico-quay-crd.yaml 
kubectl get pods -Aw
setenforce 0
```


https://www.redhat.com/architect/how-kubernetes-creates-runs-containers

https://developers.redhat.com/blog/2019/01/15/podman-managing-containers-pods#podman_pods__what_you_need_to_know

## 명령어 준비


```bash
[root@master1 ~]# kubeadm completion bash > /etc/bash_completion.d/kubeadm.sh
[root@master1 ~]# kubectl completion bash > /etc/bash_completion.d/kubectl.sh
[root@master1 ~]# complete -rp

## 쉘 변수로 사용(admin)
master]# ls -l /etc/kubernetes/
> admin.conf
master]# export KUBECONFIG=/etc/kubernetes/admin.conf

## 파일로 사용(admin)
master]# mkdir -p ~/.kube/
master]# cp /etc/kubernetes/admin.conf ~/.kube/config

master]# kubectl get nodes
```


- kubelet(hosted)
- kube-proxy(containerd, static-pod, network)
- kube-scheduler(containerd, static-pod, pod/container create)
- kube-controller-manager(containerd, static-pod, resource manage )
- kube-apiserver(containerd, static-pod, API 요청)

coredns(domain server)

etcd(kubernetes D/B key-pair+master)
= 마스터 서버는 무조건 3대



# DAY 2

## 제품환경에 대해서 잠깐...

네트워크
---
* API/Mgmt: 1G+
* Storage: 10G+(30G)
* backup: 10G+
* provision: 3G+
* ingress: 3G+
* service: 3G+

Kubernetes-OVN(OVS)

컨트롤(label: control-plane)
---
1. LoadBalancer: Hardware(L4/L7), Software(HAProxy(UDP/TCP), Nginx(TCP), Pacemaker(VIP))
2. control-plane: 3EA(ETCD)

인프라(label: infra, 10G+)
---
1. bind/dnsmasq(named, ingress, metallb)
  - PTR/SRV
2. repository(disconnected installation)
  - kubernetes image
  - calico, ingress, istio
  - buildah, skopeo, podman(workstation)
3. CI/CD
  - Harbor(image)
  - Jenkins/Tekton
  - ArgoCD/Kraken
4. Authentication
  - .X509
  - LDAP
  - OpenAuth(JWT...)
  - OpenStack Keystone
5. Storage
  - GlusterFS
  - Ceph(rook)
  - Moonfs
  - OpenStack Cinder
  - NFS 4.x


컴퓨트(label: compute, 10G+)
---
1. compute x 5EA


## 클러스터 확인


```bash

kubectl get namespaces            ## kubectl get ns
kubectl run test-pod --image=nginx
kubectl get pod                   ## kubectl get pod --namespace=default
kubectl describe pod/test-pod     ## kubectl describe pod test-pod

grep -Ev '^#|^$' /etc/containers/registries.conf
> unqualified-search-registries = ["registry.fedoraproject.org", "registry.access.redhat.com", "docker.io"]
vi /etc/containers/registries.conf
> ["quay.io", "docker.io"]

kubectl run test-apache-3 --image=quay.io/centos7/httpd-24-centos7

kubectl delete pod --all

dnf install -y epel-release
dnf install -y git yamllnit
curl -sS https://webi.sh/vim-ale | sh

```

TOML: INI형태로 사용하였던 설정, TOML

JSON: 개발 데이터 핸들링(reset)

YAML: 인프라 데이터 핸들링(automation)

```yaml
vi deployment.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment  ## Pod이름, crictl pods ls
spec:                     ## Pod사양
  selector:               ## replicaset에서 바로볼 자원
    matchLabels:
      app: nginx
  replicas: 2             ## 복제할 개수(replicaset, rs)
  template:               ## deployment에서 사용하는 설정
    metadata:
      labels:
        app: nginx        ## deployment 레이블
    spec:
      containers:         ## 컨테이너 사양
      - name: nginx       ## 컨테이너 이름, crictl ps 
        image: nginx:1.14.2       ## 컨테이너 이미지
        ports:
        - containerPort: 80       ## 컨테이너 애플리케이션 포트, 포트는 POD에서 관리

kubectl apply -f deployment.yaml
```


```bash
kubectl create deployment test-deployment --dry-run=client --output=yaml --image=nginx --replicas=10 --port=80 --namespace=default > test-deployment.yaml
```


## 네임스페이스

```bash
kubectl create namespace test1
kubectl config set-context --current --namespace=test1
kubectl run test1-pod --image=nginx --namespace=test1

kubectl delete namespace test1

kubectl create namespace test1 --dry-run=client -o=yaml > test1-pod.yaml
kubectl run test1-pod --image=nginx --namespace=test1 --dry-run=client -o=yaml >> test1-pod.yaml 
```

```yaml
---
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: null
  name: test1
spec: {}
status: {}
---
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: test1-pod
  name: test1-pod
  namespace: test1
spec:
  containers:
  - image: nginx
    name: test1-pod
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
```

1.[레드햇 Podman ebook](https://developers.redhat.com/e-books/podman-action)
2.[컨테이너 기본](https://github.com/tangt64/training_memos/tree/main/opensource-101/oci-podman-101)

## 용어 정리

1. low level container(runtime): __crio__, containerd. 저수준 컨테이너는 API기능을 지원하지 않음. 보통 소켓 기반으로 통신. CRI socket지원을 해야 쿠버네티스와 연동이 가능. 컨테이너 구성 자동화.
2. high level container(engine): API기능 지원 및 확장 도구. 예를 들어서 이미지 빌드, 이미지 검색, 이미지 저장, 컨테이너 조작 기능. podman, docker.
3. conmon: lifecycle of Linux containers. Open Container Initiative (OCI) format, 도커 이미지.
4. runc: Open Container Initiative runtime. 실질적으로 컨테이너를 구성.
5. app-container: 일반 컨테이너 이미지
6. infra-container: pause 프로그램이 실행되는 이미지. Pod를 구성 및 생성.


## apply, create

create는 일회성으로 자원을 생성.
- 업데이트가 안됨.
```bash
kubectl create -f ns-basic.yaml
kubectl create -f ns-basic.yaml        ## 이미 생성이 되어있다고 메세지가 출력.
```

apply는 기존의 정보에 applied기록을 남기면서 업데이트가 가능함.
```bash
kubectl apply -f ns-basic.yaml
kubectl apply -f ns-basic.yaml

kubectl edit namespace/ns-basic
```

```bash
kubectl create deployment my-httpd --image=quay.io/centos7/httpd-24-centos7 --port=80 --dry-run=client -o=yaml > my-httpd.yaml
vi my-httpd.yaml
> containers:
>   name: httpd
kubectl apply -f my-httpd.yaml
```


# DAY 3

# DAY 4