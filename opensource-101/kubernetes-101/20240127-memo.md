# 쿠버네티스 메모

# 우분투 20.04

## 설치 명령어 정리

```bash
sudo hostnamectl set-hostname master.example.com
sudo hostnamectl set-hostname node1.example.com

sudo cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system

lsmod | grep br_netfilter
lsmod | grep overlay
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward

sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
sudo mkdir -m 755 /etc/apt/keyrings

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.27/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb  [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.27/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

sudo echo 'deb http://deb.debian.org/debian buster-backports main' > /etc/apt/sources.list.d/backports.list
sudo apt update




## 아래 명령어는 루트에서 실행

```bash
export OS=xUbuntu_20.04
export VERSION=1.27.0

curl -fsSL  https://mirrorcache-jp.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.27:/1.27.0/xUbuntu_20.04/Release.key | apt-key add -

curl -fsSL  https://mirrorcache-jp.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_20.04/Release.key | apt-key add -

echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.27:/1.27.0/xUbuntu_20.04/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list
apt update
apt-get install cri-o cri-o-runc -y

systemctl enable --now crio
systemctl enable --now kubelet

cat <<EOF> /etc/netplan/01-enp2s0.yaml 
network:
  version: 2
  renderer: networkd
  ethernets:
    enp2s0:
      dhcp4: no
      addresses:
        - 192.168.90.110/24
EOF
netplan apply

cat <<EOF>> /etc/hosts
192.168.90.100 master.example.com master
192.168.90.110 node1.example.com node2
EOF

## 만약, firewalld가 설치 되어 있으면 중지

systemctl stop firewalld
systemctl disable firewalld
systemctl is-active firewalld

swapoff -a 
```
## 쿠버네티스 설치

```bash
kubeadm init --apiserver-advertise-address=192.168.90.100 --pod-network-cidr=192.168.0.0/16 --service-cidr=10.90.0.0/16

## 네트워크 구성(calico기반)

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/tigera-operator.yaml
curl https://raw.githubusercontent.com/tangt64/training_memos/main/opensource-101/kubernetes-101/calico-quay-crd.yaml -o calico-quay-crd.yaml 
kubectl apply -f calico-quay-crd.yaml 
```

## 메트릭/역할

```bash
kubectl create -f https://raw.githubusercontent.com/tangt64/training_memos/main/opensource/kubernetes-101/files/metrics.yaml
kubectl label node node1.example.com node-role.kubernetes.io/worker=worker
kubectl label node node2.example.com node-role.kubernetes.io/worker=worker
kubectl top nodes
kubectl get nodes
```

## 확인하기(마스터)

```bash
export KUBECONFIG=/etc/kubernetes/admin.conf 
kubectl get nodes
```

## 쿠버네티스 프록시 서비스 및 포트 포워드

```bash
kubectl create ns proxy-nginx-lab
kubectl run proxy-nginx --port=80 --image=nginx -n  ns proxy-nginx-lab
kubectl port-forward pod/proxy-nginx --address=0.0.0.0 8080:80 -n  ns proxy-nginx-lab
```



# 레드햇 계열

## 설치 명령어 정리
## 쿠버네티스 싱글 마스터 + 2노드 클러스터 구성(kubeadm)

- kubespray(ansible)
- kind
- minikube

## 마스터 및 노드 공통 설정

```bash
master/node]# cat <<EOF> /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.26/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.26/rpm/repodata/repomd.xml.key
# exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
master/node]# dnf search --disableexcludes=kubernetes kubectl kubeadm kubelet 
master/node]# dnf install --disableexcludes=kubernetes kubectl kubeadm kubelet 
master/node]# setenforce 0
master/node]# vi /etc/selinux/config
> permissive
```

```bash
master/node]# systemctl stop firewalld && systemctl disable firewalld
master/node]# swapon -s
master/node]# swapoff -a
master/node]# dnf install tc -y        			 		## optional
master/node]# dnf install iproute-tc -y 				## centos-9-stream, optional
```

### hosts A Recode(instead bind)
1. bind(dns) 구성(primary)
2. /etc/hosts A(ipv4),AAAA(ipv6) recode를 구성(backup)

```bash
#
# 내부 아이피로 구성
#
master/node]# cat <<EOF>> /etc/hosts
192.168.90.110 master.example.com master

192.168.90.120 node1.example.com node1
192.168.90.130 node2.example.com node2
EOF
```
### kubelet service

__처음에 동작 시 "activing..."라고 표시가 되는것은 지극히 정상__

```bash
master]# systemctl status kubelet
master]# systemctl enable --now kubelet
```

### crio install(o)

```bash
master/node]# cat <<EOF> /etc/yum.repos.d/libcontainer.repo
[devel_kubic_libcontainers_stable]
name=devel_kubic_libcontainers_stable
type=rpm-md
baseurl=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_9_Stream/
gpgcheck=1
gpgkey=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_9_Stream/repodata/repomd.xml.key
enabled=1
EOF


master/node]# cat <<EOF> /etc/yum.repos.d/crio_stable.repo
[crio]
name=cri-o for derivatives RHEL
type=rpm-md
baseurl=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.24:/1.24.6/CentOS_8/
gpgcheck=1
gpgkey=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.24:/1.24.6/CentOS_8/repodata/repomd.xml.key
enabled=1
EOF
master/node]# dnf install cri-o -y
master/node]# systemctl enable --now crio
master/node]# systemctl is-active crio


```
### modules

```bash
master/node]# modprobe br_netfilter    ## bridge for iptables or nftables, L2/L3
master/node]# modprobe overlay         ## cotainer image for UFS(overlay2), Disk(UFS)
master/node]# cat <<EOF> /etc/modules-load.d/k8s-modules.conf
br_netfilter
overlay
EOF
```

### kenrel parameter
```bash
master/node]# cat <<EOF> /etc/sysctl.d/k8s-mod.conf
> net.bridge.bridge-nf-call-iptables=1    ## container ---> link ---> tap ---> bridge
> net.ipv4.ip_forward=1                   ## pod <---> svc
> net.bridge.bridge-nf-call-ip6tables=1   ## ipv6
> EOF
sysctl --system                           ## 재부팅 없이 커널 파라메타 수정하기
dracut -f 								  ## ramdisk 갱신
```

### kubeadm init as single controller role node

```bash
master]# kubeadm init --apiserver-advertise-address=192.168.90.110 --pod-network-cidr=192.168.0.0/16 --service-cidr=10.90.0.0/16
master]# systemctl is-active kubelet  							## active
master]# crictl ps 
```
### 초기화 순서 및 방법

노드에서 마스터 순서로 리셋.
```bash
@master]# kubeadm reset --force 
@node]# kubeadm reset --force
```

### kubeadm join(single)

```bash
@master]# KUBECONFIG=/etc/kubernetes/admin.conf kubeadm token create --print-join-command
```

### node join

```bash
kubeadm join 192.168.90.110:6443 --token yspx54.k2076yehis972cng \
        --discovery-token-ca-cert-hash sha256:4743574ead43b14374be00496294bcb5ee85a3967724c0c3464ca9dcb576fb27
kubectl get nodes    
```
### 터널링 네트워크 구성

```bash
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
wget https://raw.githubusercontent.com/tangt64/duststack-k8s-auto/master/roles/cni/cni-calico/templates/custom-resources.yaml
vi custom-resources.yaml
> cidr: 192.168.0.0/16
kubectl apply -f custom-resources.yaml
```

#### 메트릭/역할(임시)
```bash
kubectl create -f https://raw.githubusercontent.com/tangt64/training_memos/main/opensource/kubernetes-101/files/metrics.yaml
kubectl label node node1.example.com node-role.kubernetes.io/worker=worker
kubectl label node node2.example.com node-role.kubernetes.io/worker=worker
kubectl top nodes
kubectl get nodes
```
- 노드 1번에 쿠버네티스/CRIO/모듈/커널 파라메타/방화벽/kubelet 등 서비스 설정
- 마스터에서 token create로 조인 명령어 생성 후, 노드1에서 실행

#### 확인하기(마스터)
```bash
export KUBECONFIG=/etc/kubernetes/admin.conf 
kubectl get nodes
```





# 연습문제

```bash
kubectl config set-context --current
````

- 네임스페이스 생성 및 자원 생성-1
  + 네임스페이스 exam-only-pod
  + pod3개 생성(pod1, pod2, pod3)
  + 레이블 run: pod로 설정되어 있는 pod를 모두 찾아서 report/run-pods.txt로 저장
  + 모든 Pod는 sleep 100000으로 동작
  
```bash
kubectl run pod-{1..4} --image=quay.io/centos/centos:stream9 --labels=run=pod -- sleep 10000
```

- 네임스페이스 생성 및 자원 생성-2
  + exam-pratice-1 네임스페이스 생성
  + Nginx Pod를 생성(nginx:1.24.0-alpine3.17-slim)
  + 메세지 "hello CKA" 출력(alpine:3.17)
  + 메세지 출력이 올바르게 되지 않으면, 해당 메세지를 "exam-alpine-msg-error.txt"파일로 report디렉터리 생성 후, 내용 남기기




```bash
kubectl run --dry-run=client --namespace=<NS_NAME> --output=yaml > <FILENAME>
kubectl set-context --current --namespace=<NS_NAME>

kubectl describ pod/<POD_NAME>
kubectl logs <POD_NAME>
kubectl run exam-alpine-msg-1 --image=alpine:3.17 --namespace=exam-pratice-1 --dry-run=client --output=yaml echo "hello CKA" > exam-alpine-msg.yaml
```  
- 디플로이먼트 자원 생성-1
  +  Nginx Pod를 생성. 이미지는 "nginx:1.24.0-alpine3.17-slim" 사용
  +  모든 Pod는 "exam-1-deploy-nginx" deployment으로 생성
  +  Pod의 시작 개수는 총 3개로 생성 및 동작
  +  모든 Pod는 label "lab"라는 키워드에 "exam-1"이라는 값을 가지고 있다
  +  레이블이 올바르게 등록이 되었는지 확인(deployment, pod)
  +  해당 Pod는 외부에서 접근이 가능해야 한다(80/TCP)

```bash
kubectl create exam-1-deploy-nginx --image=nginx:1.24.0-alpine3.17-slim
kubectl create deployment exam-1-deploy-nginx --image=nginx:1.24.0-alpine3.17-slim --replicas=3 --namespace=exam-pratice-1 --port=80 --dry-run=client --output=yaml > exam-1-deploy-nginx.yaml
kubectl create deployment exam-1-deploy-nginx --image=nginx:1.24.0-alpine3.17-slim --replicas=3 --namespace=exam-pratice-1 --dry-run=client --output=yaml --port=80 > exam-1-deploy-nginx.yaml
## 레이블 관련된 부분은 별도로 추가
```

- 디플로이먼트 자원 생성-2
  + 네임스페이스는 exam-nginx-1으로 생성
  + Nginx Pod를 생성. 이미지는 "nginx:1.24.0-alpine3.17-slim" 사용
  + 모든 Pod는 "exam-nginx-1"값 및 키워드 이름은 "type"으로 deployment으로 생성
  + Pod의 시작 개수는 총 2개로 생성 및 동작
  + 레이블이 올바르게 등록이 되었는지 확인(deployment, pod)
  + 해당 Pod는 외부에서 접근이 가능해야 한다(80/TCP)
  + Pod목록에 있는 내용을 report/exam-nginx-pod-list.txt로 저장


- 초기화 컨테이너
  + 네임스페이스는 exam-init-1으로 생성
  + 초기화 컨테이너는 "busybox:1.28"사용. 메세지 "hello init container"출력
  + 애플리케이션 컨테이너 "nginx:1.24.0-alpine3.17-slim" 이미지 사용.
  + 초기화 컨테이너 동작 후, "nginx"컨테이너는 계속 동작
  + Pod의 이름 "exam-init-container-1"으로 구성
  + 레이블은 type: init으로 구성

```bash
kubectl apply -f init-myapp.yaml
kubectl get pod -w

```
```yaml
vi init-myapp.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app.kubernetes.io/name: MyApp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running!']
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: ['sh', '-c', "echo 1"]
  - name: init-mydb
    image: busybox:1.28
    command: ['sh', '-c', "echo 2"]
```

```bash

|  StorageClass  |    |  PV  |        |   PVC   |
 

```

- pv, pvc, pod 생성
  + 네임스페이스 exam-localstorage-pvpvc를 생성한다
  + 위의 프로젝트에 exam-pv, exam-pvc 이름으로 PV/PVC자원을 생성한다
  + PV/PVC 크기는 100기가, 접근 방식은 ReadWriteMany로 구성한다
  + 이 네임스페이스에서는 스토리지 클래스 구성 및 사용이 불가능하다
  + Pod는 nginx이미지를 사용하며, 웹 페이지는 "/usr/share/nginx/html"에서 불러온다. 
  + 디스크는 "/usr/share/nginx/html"에 연결 및 구성이 된다.
  + nodeb에 "/html"디렉터리에 "index.html"파일이 있으면, 내용은 "Hello PVC world"를 텍스트로 가지고 있다.
  + 위의 구성이 올바르게 구성이 되면 describe를 통해서 마운트 상태를 확인한다.